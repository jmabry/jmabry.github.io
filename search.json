[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Joshua Mabry",
    "section": "",
    "text": "I am a data scientist and engineer with experience spanning consulting, biotech, and academic research.\nI like building large-scale systems that blend experimentation, modeling, and optimization. I have designed and analyzed thousands of experiments throughout my career and so I try to keep adding to this spike, while picking up other tools I need to be effective (MLOps, Causal Inference, Cloud / Data Engineering, GenAI…).\nOn this blog, I share technical insights from building ML systems, code snippets, and the occasional thoughts on working as a data science and engineering leader."
  },
  {
    "objectID": "posts/mab-post/index.html",
    "href": "posts/mab-post/index.html",
    "title": "ML Strategy: Bandits for Personalization",
    "section": "",
    "text": "Originally appeared on Bain.com."
  },
  {
    "objectID": "posts/mab-post/index.html#at-a-glance",
    "href": "posts/mab-post/index.html#at-a-glance",
    "title": "ML Strategy: Bandits for Personalization",
    "section": "At a Glance",
    "text": "At a Glance\n\nMarketing teams often lack the ability to quickly run in-market tests and scale them up.\nTraditional A/B testing and even multivariate testing fall short for marketing that has frequent customer touches.\nMultiarmed bandits, by contrast, dynamically steer traffic toward winning marketing messages, decreasing the cost of testing due to lost conversions.\nPricing experiments are a particularly useful application since retailers must balance the need for a demand model that informs long-term profits without compromising immediate profits.\n\n\nWith third-party cookies on the wane, marketers rely increasingly on first-party data. Most retailers are investing heavily in platforms to capture and unify their customer data. Across the board, they have been reaping value from triggered campaigns, with simple purposes such as reminding customers to return to their abandoned carts or to consider relevant product assortments.\nNow, there’s a broader opportunity—namely, to use artificial intelligence (AI) to segment customers and automatically orchestrate aspects of their customer experience, ranging from marketing messages to retention interventions. Yet while many companies talk about creating a deeply personalized experience, few have made good use of AI.\nWorse, many have invested in advanced marketing technology stacks, but they cannot take advantage of the personalization capabilities advertised by platform providers. The main constraint: Marketing teams often lack the ability to quickly run in-market tests and scale up these systems through automation."
  },
  {
    "objectID": "posts/mab-post/index.html#enter-the-multiarmed-bandit",
    "href": "posts/mab-post/index.html#enter-the-multiarmed-bandit",
    "title": "ML Strategy: Bandits for Personalization",
    "section": "Enter the multiarmed bandit",
    "text": "Enter the multiarmed bandit\nWe attribute the testing bottleneck to a reliance on traditional A/B testing approaches. These tend to be highly manual to set up, implement, and interpret. Moreover, the insights generated may be ephemeral because of shifting consumer preferences and underlying seasonality in many markets. Companies that send daily messages to customers see steep decay curves as even the highest-performing messages lose effectiveness by the third time someone sees them.\nMoreover, multivariate testing (MVT), which is a more powerful approach that can test many variables at once, also suffers from this flaw as the huge lift that it generates erodes with frequent customer touches. MVT can, however, work well for marketing touches that occur infrequently for an individual consumer, such as a subscription.\nMarketers can gain greater value by adopting adaptive experimentation approaches that more efficiently optimize customer engagement or financial metrics. These highly automated and always-on tools dynamically steer traffic toward winning marketing messages, decreasing the cost of testing caused by lost conversions. We have seen retailers realize double-digit sales increases by setting their ambitions higher and by automating the testing process using these advanced approaches. One of the most effective algorithms is the multiarmed bandit (MAB), which can be applied to use cases ranging from offer optimization to dynamic pricing. Because the MAB is always optimizing, we see persistent lift even for daily customer contacts (see Figure 1).\n\n\n\nFigure 1: Multiarmed bandit has several benefits over traditional A/B or multivariate testing\n\n\nMABs provide a simple, robust solution for sequential decision making during periods of uncertainty. To build an intelligent and automated campaign, a marketer begins with a set of actions (such as which coupons to deliver) and then selects an objective (such as maximizing clickthrough rates or EBITDA for email marketing). The algorithm balances exploration (gathering more data on new actions) with exploitation (selecting actions that perform well). The goal here is to select actions that maximize the payoff and quickly converge on the best set of actions. As market conditions change, the campaigns can easily be reset to discover new winners, or in more sophisticated designs, they can be configured to continue the testing cycle indefinitely.\nPricing experiments are a particularly useful application since retailers must balance the need for a demand model that informs long-term profits without compromising immediate profits. They thus “earn while learning” through in-market tests rather than “learn then earn.” As with any learning algorithm, it is important to be thoughtful about objective functions. For instance, an objective tied to revenue rather than profit may lead the MAB to converge on a solution with excessive discounting if the algorithm decides that deep discounts are a great way to increase revenue."
  },
  {
    "objectID": "posts/mab-post/index.html#online-service-applications",
    "href": "posts/mab-post/index.html#online-service-applications",
    "title": "ML Strategy: Bandits for Personalization",
    "section": "Online service applications",
    "text": "Online service applications\nCompanies often use bandit solutions to speed up experimentation and personalize the experience for users of online services. Such solutions share a few characteristics:\nThey make several actions, such as unique ads or email messages, available for different users. Marketers can quickly track user response to the action. Marketers can easily adapt the online system, such as when recommending a different product, at a low cost. In their most basic form, MABs serve as a more efficient alternative to A/B testing, adaptively allocating traffic to find a winning version of a website, email, advertisement, or other marketing action. In most digital systems, each user interaction also gathers some side information about the user and the action, known as the context. This might be information about the user’s current circumstance (cohort, location, time of day) or historically computed information (past spending, age, gender, shopping history). Contextual bandits extend the MAB framework and learn how to use this additional information to make decisions that optimize a target metric, such as profits or clickthrough rate."
  },
  {
    "objectID": "posts/mab-post/index.html#personalization-with-contextual-bandits",
    "href": "posts/mab-post/index.html#personalization-with-contextual-bandits",
    "title": "ML Strategy: Bandits for Personalization",
    "section": "Personalization with contextual bandits",
    "text": "Personalization with contextual bandits\nLeading digital organizations implement contextual bandits for core services, such as promotional offer selection, in which it’s important to personalize the experience and adjust to fast-changing market conditions. The leaders also generate a steady stream of innovative content to test: new creative, imagery, promotions, and products. Constantly feeding the bandit with new ideas to test helps to avoid getting stuck with less-than-optimal results and generates new insights into customer behavior. Also, because bad ideas fail fast while winners rise to the top, companies can take bigger risks with their marketing ideas than they could in a slower-moving test cycle.\nThere are a few signals that a company is ready for more advanced approaches such as a contextual bandit: - a robust and fast-moving experimentation program; - customer data that can be accurately matched to historical marketing and transactional records; and - product-focused teams that can optimize high-value customer touchpoints.\nTaking on the complexity of a bandit makes sense for an organization already running tests at scale, and the traditional testing generates valuable digital exhaust that can be fed into the bandit algorithm. One typically trains a contextual bandit on logged data stored in a data warehouse or other analytical data storage. Here, a company needs records of marketing actions served (such as which coupon was sent) and the resulting reward metric at the individual customer level, as well as metadata describing both the action and the user history at the time of campaign execution.\nWith data in hand, a bandit model can be trained on any modern machine learning (ML) platform with model training, versioning, and serving capabilities. Usually, the value is established by building a minimum viable product algorithm operating on batches of data at a cadence that allows for careful validation by data science teams before being put into production. Personalized marketing messages can be served through web, email, or application-specific channels, and often there is some application programming interface (API) development work required to integrate the ML models with these channels. Luckily, most of the channel-specific tools include personalization APIs, which populate the personalized content within a message template, so these integration tasks are relatively straightforward.\nAs with any ML/AI system, continuous monitoring and ongoing maintenance remain important, so these systems are most effective in the hands of stable, product-focused marketing teams. Looking ahead, we expect to see broader adoption of AI and adaptive experimentation techniques, from which marketers can more effectively learn and activate first-party customer data."
  },
  {
    "objectID": "posts/numpyro-masking/index.html",
    "href": "posts/numpyro-masking/index.html",
    "title": "Masked Observations with Numpyro",
    "section": "",
    "text": "For building Bayesian models, NumPyro offers flexibility, speed, and near limitless extensiblity. There is a price to pay to for all that power as the API can at times be intimidating and hard to decipher. Some of the most important building blocks in Numpyro are effect handlers. Effect handlers allow us to modify how random variables are conditioned, sampled, or observed inside our probabilistic program.\nWhile working on building factorized models for predicting consumer-level purchasing behavior, I ran across the need to use the mask handler so that I could mask certain observations during modeling training. I couldn’t find any minimal examples on how to use the handler that gave me confidence I really understood the intendend usage pattern so I created a simulated dataset to test it out."
  },
  {
    "objectID": "posts/numpyro-masking/index.html#problem-setup-and-model-description",
    "href": "posts/numpyro-masking/index.html#problem-setup-and-model-description",
    "title": "Masked Observations with Numpyro",
    "section": "Problem Setup and Model Description",
    "text": "Problem Setup and Model Description\nWe are interested in building a factorized model of retail shopping, where a customer with features \\(X\\) decides whether or not to visit a store and which items in the store to purchase if they do visit. This means that to train the item choice model, we will want to mask observations from any customers that choose not to visit the store.\nLet \\(X \\in \\mathbb{R}^D\\) be a vector of features of length \\(D\\). We aim to model the joint probability \\(P(Y_0, Y_1 | X)\\) where:\n\n\\(Y_0\\) is a binary outcome.\n\\(Y_1 \\in \\{0, 1\\}^I\\) is a vector of binary outcomes of length \\(I\\).\n\nAssuming that the item choice is conditionally independent of the store visite decision, we decompose the joint probability as \\[\nP(Y_0, Y_1 \\mid X)= P(Y_0 \\mid X) \\times P(Y_1 \\mid Y_0 = 1, X)\n\\]\nIf you are interested in the full details of how to simulate data from this model and how to define it, see the notebook at jmabry/datasci-playground/numpyro_masking/."
  },
  {
    "objectID": "posts/numpyro-masking/index.html#numpyro-model-with-masking",
    "href": "posts/numpyro-masking/index.html#numpyro-model-with-masking",
    "title": "Masked Observations with Numpyro",
    "section": "NumPyro model with masking",
    "text": "NumPyro model with masking\nThe NumPyro model that allows for masked observations is defined as follows:\ndef _logit_choice_model(X, name_prefix, n_outputs):\n    n_features = X.shape[1]\n    beta = numpyro.sample(f'{name_prefix}_beta', dist.Normal(jnp.zeros((n_outputs, n_features)), jnp.ones((n_outputs, n_features))))\n    intercept = numpyro.sample(f'{name_prefix}_intercept', dist.Normal(jnp.zeros(n_outputs), 1.))\n    linear_combination = jnp.einsum('ij,kj-&gt;ik', X, beta) + intercept\n    return jax.nn.sigmoid(linear_combination)\n\ndef mask_handler_model(X, I, y0=None, y1=None):\n    \"\"\"Model of joint store visit and item choice decisions.\n    \"\"\"\n    # Model P(Y0 | X)\n    P_Y0 = _logit_choice_model(X, 'Y0', 1).squeeze()\n\n    # Sample Y0\n    y0_sample = numpyro.sample('y0', dist.Bernoulli(P_Y0), obs=y0)  \n\n    # Masking to filter out Y1 calculations when Y0 is 0\n    mask_array = (y0_sample == 1)[:, None]\n\n    # Model P(Y1 | Y0 = 1, X)\n    P_Y1_given_Y0 = _logit_choice_model(X, 'Y1_given_Y0', I)  \n\n    with numpyro.plate('products', I, dim=-1):\n        with numpyro.plate('data_y1', X.shape[0]):\n            with mask(mask=mask_array):\n               numpyro.sample('y1', dist.Bernoulli(P_Y1_given_Y0), obs=y1)\nTo validate that the model works correctly, we can run MCMC sampling to obtain estimates of the model parameters and compare them to the ground truth values defined in our simulation. Running a toy simulation with 10,000 observations of customers with 3 descriptive features, choosing from 2 items. We get the following parameter estimates, where each row represents a different parameter from the hierarchical model:\n                      ground_truth    mean     sd\nY0_beta[0, 0]               0.371    0.355   0.025\nY0_beta[0, 1]               0.305    0.290   0.026\nY0_beta[0, 2]               0.504    0.476   0.026\nY0_intercept[0]             1.353    1.345   0.026\nY1_given_Y0_beta[0, 0]     -2.474   -2.559   0.061\nY1_given_Y0_beta[0, 1]     -1.463   -1.450   0.047\nY1_given_Y0_beta[0, 2]      1.257    1.283   0.043\nY1_given_Y0_beta[1, 0]      2.197    2.290   0.054\nY1_given_Y0_beta[1, 1]     -0.647   -0.650   0.037\nY1_given_Y0_beta[1, 2]      0.478    0.456   0.036\nY1_given_Y0_intercept[0]    0.449    0.517   0.039\nY1_given_Y0_intercept[1]    0.887    0.953   0.035\nWe see that the parameter estimates match the ground truth used to simulate the data and can feel confident that we are using the NumPyro masking effect handler as intended.\nFor the sake of comparison, failing to include the masking operation yields very poor parameter estimates as shown below:\n                      ground_truth    mean     sd\nY0_beta[0, 0]               0.371    0.355   0.025\nY0_beta[0, 1]               0.305    0.290   0.026\nY0_beta[0, 2]               0.504    0.476   0.028\nY0_intercept[0]             1.353    1.345   0.027\nY1_given_Y0_beta[0, 0]     -2.474   -1.030   0.029\nY1_given_Y0_beta[0, 1]     -1.463   -0.526   0.026\nY1_given_Y0_beta[0, 2]      1.257    0.879   0.027\nY1_given_Y0_beta[1, 0]      2.197    1.466   0.033\nY1_given_Y0_beta[1, 1]     -0.647   -0.205   0.026\nY1_given_Y0_beta[1, 2]      0.478    0.512   0.025\nY1_given_Y0_intercept[0]    0.449   -0.461   0.025\nY1_given_Y0_intercept[1]    0.887    0.016   0.024\nI hope this example can help other NumPyro amateurs learn how to use effect handlers and provides a template for validating a black-box API. Reach out to me if you have any questions!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PainpointsPurelyTechnical",
    "section": "",
    "text": "Masked Observations with Numpyro\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2024\n\n\nJoshua Mabry\n\n\n\n\n\n\n\n\n\n\n\n\nML Strategy: Bandits for Personalization\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2021\n\n\nJoshua Mabry, Rich Lichtenstein, and Janani Sriram\n\n\n\n\n\n\nNo matching items"
  }
]